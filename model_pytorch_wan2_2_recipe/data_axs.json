{
    "_parent_entries": [
        [ "^", "byname", "shell" ],
        [ "^", "byname", "entry_creator" ]
    ],

    "_producer_rules": [
        [ [ "downloaded", "pytorch_model", "model_name=wan2_2" ], [[ "get", "pipeline" ]] ]
    ],

    "pipeline": [ "^^", "execute", [[
        [ "run" ],
        [ ],
        [ "get", "stored_newborn_entry" ]
    ]] ],

    "newborn_name_template": "downloaded_pytorch_model_wan2_2",

    "mlperf_inference_git_entry": [ "^", "byquery", "git_repo,repo_name=mlperf_inference_git" ],

    "launch_script_entry": [ "^", "byname", "base_text_to_video_loadgen_experiment" ],
    "launch_script_path": [ "^^", "execute", [[
        [ "get", "launch_script_entry" ],
        [ "get_path", [ "launch.sh" ] ]
    ]] ],

    "file_name": [ "^^", "get", "mlperf_model_name" ],

    "model_name": "wan2_2",
    "model_family": "Wan-AI",
    "mlperf_model_name": "Wan2.2-T2V-A14B-Diffusers",
    "full_mlperf_model_name": [ "^^", "substitute", "#{model_family}#/#{mlperf_model_name}#" ],
    "model_path": "/model",

    "retrained": "No",
    "input_data_types": "fp16",
    "weight_data_types": "fp16",
    "weight_transformations": "No",
    "url": "https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B-Diffusers",

    "download_model_script_name": "download_model.py",

    "build_container": [ "^^", "substitute", "#{launch_script_path}# --build" ],
    "download_model":  [ "^^", "substitute", "#{launch_script_path}# -v #{newborn_entry_path}#:#{model_path}# python3 #{download_model_script_name}# --download-path #{model_path}# --model-name #{full_mlperf_model_name}#" ],

    "newborn_entry_param_names": [
        "file_name"
    ],

    "dockerfile_entry": [ "^", "byname", "base_text_to_video_loadgen_experiment" ],
    "dockerfile_path": [ "^^", "execute", [[
        [ "get", "dockerfile_entry" ],
        [ "get_path" ]
    ]] ],

    "inference_root": [ "^^", "execute", [[
        [ "get", "mlperf_inference_git_entry" ],
        [ "get_path", [[ "text_to_video" ]] ]
    ]] ],

    "env": {
        "WORK_DIR": [ "^^", "get", "dockerfile_path" ],
        "INFERENCE_ROOT": [ "^^", "get", "inference_root" ]
    },

    "shell_cmd": [ "^^", "substitute",
        "#{build_container}# && #{download_model}#"
    ]
}
